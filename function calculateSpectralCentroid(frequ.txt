function calculateSpectralCentroid(frequencies,magnitudes){let weightedSum=0;let totalMagnitude=0;for(let i=0;i<frequencies.length;i++){weightedSum+=frequencies[i]*magnitudes[i];totalMagnitude+=magnitudes[i];}return totalMagnitude===0?0:(weightedSum/totalMagnitude).toFixed(2);}
function calculateRMS(samples){try{if(!Array.isArray(samples)||samples.length===0){throw new Error("Invalid input: samples must be a non-empty array.");}const squaredSum=samples.reduce((sum,sample)=>sum+sample*sample,0);return Math.sqrt(squaredSum/samples.length).toFixed(2);}catch(error){console.error("Error calculating RMS:",error);return null;}}
function calculateHarmonicRatio(frequencies,magnitudes){try{if(!Array.isArray(frequencies)||!Array.isArray(magnitudes)||frequencies.length!==magnitudes.length){throw new Error("Invalid input: frequencies and magnitudes must be arrays of the same length.");}let harmonicEnergy=0;let totalEnergy=magnitudes.reduce((sum,mag)=>sum+mag,0);for(let i=1;i<frequencies.length;i++){if(frequencies[i]%frequencies[0]===0){harmonicEnergy+=magnitudes[i];}}return (harmonicEnergy/totalEnergy*100).toFixed(2);}catch(error){console.error("Error calculating Harmonic Ratio:",error);return null;}}
function extractMetadata(file){try{const metadata={};if(!file)throw new Error("File is invalid for metadata extraction.");metadata.artist="Example Artist";metadata.album="Example Album";metadata.genre="Example Genre";return metadata;}catch(error){console.error("Error extracting metadata:",error);return {};}}
function extractDuration(file){return new Promise((resolve,reject)=>{try{const audio=new Audio();audio.src=URL.createObjectURL(file);audio.onloadedmetadata=function(){resolve(audio.duration);};audio.onerror=function(){reject('Error extracting audio duration.');};}catch(error){reject("Error loading audio file for duration extraction: "+error);}});}
function extractBitrate(file){try{if(!file)throw new Error("Invalid file for bitrate extraction.");return 320;}catch(error){console.error("Error extracting bitrate:",error);return null;}}
const wavesurfer=WaveSurfer.create({container:'#waveform',waveColor:'violet',progressColor:'purple',height:150});
function loadWaveform(file){try{if(!file)throw new Error("Invalid file for waveform display.");wavesurfer.load(URL.createObjectURL(file));}catch(error){console.error("Error loading waveform:",error);}}
function plotRMS(rmsValues,timeLabels){try{const ctx=document.getElementById('rmsChart').getContext('2d');const rmsChart=new Chart(ctx,{type:'line',data:{labels:timeLabels,datasets:[{label:'RMS',data:rmsValues,borderColor:'rgba(75, 192, 192, 1)',fill:false}]}});}catch(error){console.error("Error plotting RMS chart:",error);}}
function detectClipping(channelData){try{if(!Array.isArray(channelData))throw new Error("Invalid audio data for clipping detection.");const clippingThreshold=1.0;const clippingRegions=[];for(let i=0;i<channelData.length;i++){if(Math.abs(channelData[i])>=clippingThreshold){clippingRegions.push(i);}}return clippingRegions;}catch(error){console.error("Error detecting clipping:",error);return[];}}
function validateAudioData(file){try{if(!file||!file.name||!file.size){throw new Error("Invalid file: file must have a name and size.");}return true;}catch(error){console.error("File validation error:",error);return false;}}
function processAudioFile(file){if(!validateAudioData(file))return;loadWaveform(file);const audioContext=new(window.AudioContext||window.webkitAudioContext)();const reader=new FileReader();reader.onload=function(){audioContext.decodeAudioData(reader.result,function(buffer){const channelData=buffer.getChannelData(0);const rms=calculateRMS(channelData);const peakAmplitude=calculatePeakAmplitude(channelData);const zeroCrossingRate=calculateZeroCrossingRate(channelData);displayMetric("RMS",rms);displayMetric("PeakAmplitude",peakAmplitude);displayMetric("ZeroCrossingRate",zeroCrossingRate);const clippingRegions=detectClipping(channelData);if(clippingRegions.length>0){console.log("Clipping detected at regions:",clippingRegions);}});};reader.readAsArrayBuffer(file);}
function calculatePeakAmplitude(samples){const peak=Math.max(...samples);return peak.toFixed(2);}
function calculateZeroCrossingRate(signal){let zeroCrossings=0;for(let i=1;i<signal.length;i++){if(signal[i-1]*signal[i]<0){zeroCrossings++;}}return((zeroCrossings/signal.length)*100).toFixed(2);}
function displayMetric(metricName,value){const element=document.getElementById(metricName);if(element){element.innerText=`${metricName}: ${value}`;}}
const dragDropContainer=document.getElementById('dragDropContainer');dragDropContainer.addEventListener('drop',function(event){event.preventDefault();const files=event.dataTransfer.files;if(files.length>0){analyzeFile(files[0]);}});dragDropContainer.addEventListener('dragover',function(event){event.preventDefault();});
const fileInput=document.getElementById('fileInput');fileInput.addEventListener('change',function(event){const files=event.target.files;if(files.length>0){analyzeFile(files[0]);}});
function analyzeFile(file){const audioContext=new(window.AudioContext||window.webkitAudioContext)();const reader=new FileReader();reader.onload=function(){audioContext.decodeAudioData(reader.result,function(buffer){const channelData=buffer.getChannelData(0);const rms=calculateRMS(channelData);const peakAmplitude=calculatePeakAmplitude(channelData);const zeroCrossingRate=calculateZeroCrossingRate(channelData);displayMetric("RMS",rms);displayMetric("PeakAmplitude",peakAmplitude);displayMetric("ZeroCrossingRate",zeroCrossingRate);});};reader.readAsArrayBuffer(file);}


// Comprehensive Audio Metrics Calculations

/**
 * Calculate Spectral Centroid
 * @param {Array} frequencies - Array of frequency bins
 * @param {Array} magnitudes - Array of magnitudes corresponding to the frequencies
 * @returns {number} Spectral Centroid in Hz
 */
function calculateSpectralCentroid(frequencies, magnitudes) {
    let weightedSum = 0;
    let totalMagnitude = 0;

    // Loop through frequencies and their corresponding magnitudes
    for (let i = 0; i < frequencies.length; i++) {
        weightedSum += frequencies[i] * magnitudes[i]; // Weighted sum of frequencies
        totalMagnitude += magnitudes[i]; // Total magnitude sum
    }

    // Return the spectral centroid, if total magnitude is 0 return 0, otherwise calculate
    return totalMagnitude === 0 ? 0 : (weightedSum / totalMagnitude).toFixed(2);
}
// New JavaScript File for Enhanced Audio Metrics and Features

// Section 1: Audio Analysis Metrics

/**
 * Calculate Spectral Centroid
 * @param {Array} frequencies - Array of frequency bins
 * @param {Array} magnitudes - Array of magnitudes corresponding to the frequencies
 * @returns {number} Spectral Centroid in Hz
 */
function calculateSpectralCentroid(frequencies, magnitudes) {
    try {
        if (!Array.isArray(frequencies) || !Array.isArray(magnitudes) || frequencies.length !== magnitudes.length) {
            throw new Error("Invalid input: frequencies and magnitudes must be arrays of the same length.");
        }

        let weightedSum = 0;
        let totalMagnitude = 0;

        for (let i = 0; i < frequencies.length; i++) {
            weightedSum += frequencies[i] * magnitudes[i];
            totalMagnitude += magnitudes[i];
        }

        return totalMagnitude === 0 ? 0 : (weightedSum / totalMagnitude).toFixed(2);
    } catch (error) {
        console.error("Error calculating Spectral Centroid:", error);
        return null;
    }
}

/**
 * Calculate RMS Energy
 * @param {Array} samples - Array of audio samples
 * @returns {number} RMS Energy
 */
function calculateRMS(samples) {
    try {
        if (!Array.isArray(samples) || samples.length === 0) {
            throw new Error("Invalid input: samples must be a non-empty array.");
        }

        const squaredSum = samples.reduce((sum, sample) => sum + sample * sample, 0);
        return Math.sqrt(squaredSum / samples.length).toFixed(2);
    } catch (error) {
        console.error("Error calculating RMS:", error);
        return null;
    }
}

/**
 * Harmonic Ratio Calculation
 * @param {Array} frequencies - Array of frequency bins
 * @param {Array} magnitudes - Array of magnitudes corresponding to the frequencies
 * @returns {number} Harmonic Ratio
 */
function calculateHarmonicRatio(frequencies, magnitudes) {
    try {
        if (!Array.isArray(frequencies) || !Array.isArray(magnitudes) || frequencies.length !== magnitudes.length) {
            throw new Error("Invalid input: frequencies and magnitudes must be arrays of the same length.");
        }

        let harmonicEnergy = 0;
        let totalEnergy = magnitudes.reduce((sum, mag) => sum + mag, 0);

        for (let i = 1; i < frequencies.length; i++) {
            if (frequencies[i] % frequencies[0] === 0) {  // Simple check for harmonic frequencies
                harmonicEnergy += magnitudes[i];
            }
        }

        return (harmonicEnergy / totalEnergy * 100).toFixed(2);
    } catch (error) {
        console.error("Error calculating Harmonic Ratio:", error);
        return null;
    }
}

// Section 2: Metadata Extraction

/**
 * Extract Metadata from Audio File (e.g., artist, album, genre)
 * @param {Object} file - Audio file to extract metadata from
 * @returns {Object} Metadata object with details like artist, album, genre
 */
function extractMetadata(file) {
    try {
        const metadata = {};

        // Placeholder for actual metadata extraction, like using jsmediatags
        if (!file) throw new Error("File is invalid for metadata extraction.");

        // Mock metadata for the example (replace with real extraction logic)
        metadata.artist = "Example Artist";
        metadata.album = "Example Album";
        metadata.genre = "Example Genre";

        return metadata;
    } catch (error) {
        console.error("Error extracting metadata:", error);
        return {};
    }
}

/**
 * Extract Duration of Audio File
 * @param {Object} file - Audio file to extract the duration from
 * @returns {Promise} Promise with audio duration in seconds
 */
function extractDuration(file) {
    return new Promise((resolve, reject) => {
        try {
            const audio = new Audio();
            audio.src = URL.createObjectURL(file);

            audio.onloadedmetadata = function () {
                resolve(audio.duration); // Duration in seconds
            };

            audio.onerror = function () {
                reject('Error extracting audio duration.');
            };
        } catch (error) {
            reject("Error loading audio file for duration extraction: " + error);
        }
    });
}

/**
 * Extract Bitrate of Audio File (Placeholder)
 * @param {Object} file - Audio file to extract bitrate from
 * @returns {number} Bitrate in kbps
 */
function extractBitrate(file) {
    try {
        if (!file) throw new Error("Invalid file for bitrate extraction.");
        // Placeholder logic: Implement real bitrate extraction based on file format
        return 320; // Assume 320 kbps for now
    } catch (error) {
        console.error("Error extracting bitrate:", error);
        return null;
    }
}

// Section 3: Waveform Visualization (Using Wavesurfer.js)

// Initialize Wavesurfer for waveform visualization
const wavesurfer = WaveSurfer.create({
    container: '#waveform',
    waveColor: 'violet',
    progressColor: 'purple',
    height: 150
});

/**
 * Load Audio File into Wavesurfer
 * @param {Object} file - Audio file to load into the waveform viewer
 */
function loadWaveform(file) {
    try {
        if (!file) throw new Error("Invalid file for waveform display.");
        wavesurfer.load(URL.createObjectURL(file));
    } catch (error) {
        console.error("Error loading waveform:", error);
    }
}

// Section 4: Interactive Charting (Using Chart.js)

/**
 * Function to plot RMS using Chart.js
 * @param {Array} rmsValues - Array of RMS values
 * @param {Array} timeLabels - Time labels for the X-axis
 */
function plotRMS(rmsValues, timeLabels) {
    try {
        const ctx = document.getElementById('rmsChart').getContext('2d');
        const rmsChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: timeLabels, // Time labels for the X-axis
                datasets: [{
                    label: 'RMS',
                    data: rmsValues, // RMS values to be plotted
                    borderColor: 'rgba(75, 192, 192, 1)',
                    fill: false
                }]
            }
        });
    } catch (error) {
        console.error("Error plotting RMS chart:", error);
    }
}

// Section 5: Clipping Detection (Detect areas where clipping occurs)

/**
 * Detect Clipping in the audio data
 * @param {Array} channelData - Audio sample data
 * @returns {Array} Array of indices where clipping occurs
 */
function detectClipping(channelData) {
    try {
        if (!Array.isArray(channelData)) throw new Error("Invalid audio data for clipping detection.");
        
        const clippingThreshold = 1.0; // Clipping threshold for audio (1.0 is the max amplitude)
        const clippingRegions = [];

        for (let i = 0; i < channelData.length; i++) {
            if (Math.abs(channelData[i]) >= clippingThreshold) {
                clippingRegions.push(i); // Mark the region where clipping happens
            }
        }

        return clippingRegions;
    } catch (error) {
        console.error("Error detecting clipping:", error);
        return [];
    }
}

// Section 6: Error Handling & Validation

/**
 * Validate Audio Data Integrity
 * @param {Object} file - Audio file to validate
 * @returns {boolean} True if valid, false otherwise
 */
function validateAudioData(file) {
    try {
        if (!file || !file.name || !file.size) {
            throw new Error("Invalid file: file must have a name and size.");
        }
        return true;
    } catch (error) {
        console.error("File validation error:", error);
        return false;
    }
}

// Main function to process audio file (integrate everything)
function processAudioFile(file) {
    if (!validateAudioData(file)) return;

    // Load waveform into the viewer
    loadWaveform(file);

    // Example: Process audio file for various metrics
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const reader = new FileReader();

    reader.onload = function () {
        audioContext.decodeAudioData(reader.result, function (buffer) {
            const channelData = buffer.getChannelData(0); // Get the first channel data

            // Calculate metrics
            const rms = calculateRMS(channelData);
            const peakAmplitude = calculatePeakAmplitude(channelData);
            const zeroCrossingRate = calculateZeroCrossingRate(channelData);

            // Display metrics on the page
            displayMetric("RMS", rms);
            displayMetric("PeakAmplitude", peakAmplitude);
            displayMetric("ZeroCrossingRate", zeroCrossingRate);

            // Detect clipping and log results
            const clippingRegions = detectClipping(channelData);
            if (clippingRegions.length > 0) {
                console.log("Clipping detected at regions:", clippingRegions);
            }
        });
    };

    reader.readAsArrayBuffer(file);
}

/**
 * Calculate RMS Energy
 * @param {Array} samples - Array of audio samples
 * @returns {number} RMS Energy
 */
function calculateRMS(samples) {
    // Calculate the squared sum of the samples
    const squaredSum = samples.reduce((sum, sample) => sum + sample * sample, 0);
    // Return the square root of the average squared sum (RMS value)
    const rms = Math.sqrt(squaredSum / samples.length);
    return rms.toFixed(2); // Round to 2 decimal places
}

/**
 * Calculate Peak Amplitude
 * @param {Array} samples - Array of audio samples
 * @returns {number} Peak Amplitude
 */
function calculatePeakAmplitude(samples) {
    // Return the maximum value from the array of audio samples (peak amplitude)
    return Math.max(...samples).toFixed(2);
}

/**
 * Calculate Zero Crossing Rate
 * @param {Array} signal - Array of audio signal values
 * @returns {number} Zero Crossing Rate (percentage)
 */
function calculateZeroCrossingRate(signal) {
    let zeroCrossings = 0;

    // Loop through the signal to count zero-crossings
    for (let i = 1; i < signal.length; i++) {
        if (signal[i - 1] * signal[i] < 0) { // Detects a sign change
            zeroCrossings++; // Increment zero-crossing count
        }
    }

    // Return zero-crossing rate as a percentage of total samples
    return ((zeroCrossings / signal.length) * 100).toFixed(2);
}

/**
 * Calculate Total Energy
 * @param {Array} samples - Array of audio samples
 * @returns {number} Total Energy
 */
function calculateTotalEnergy(samples) {
    // Sum the square of each sample (energy calculation)
    const totalEnergy = samples.reduce((sum, sample) => sum + sample ** 2, 0);
    return totalEnergy.toFixed(2); // Return the total energy rounded to 2 decimal places
}

/**
 * Find Frequency Peaks
 * @param {Array} frequencies - Array of frequency bins
 * @param {Array} magnitudes - Array of magnitudes corresponding to the frequencies
 * @param {number} threshold - Minimum magnitude to consider a peak
 * @returns {Array} List of frequency peaks
 */
function findFrequencyPeaks(frequencies, magnitudes, threshold) {
    const peaks = [];
    
    // Loop through frequencies and check if magnitudes exceed threshold to consider them as peaks
    for (let i = 0; i < frequencies.length; i++) {
        if (magnitudes[i] > threshold) { // If magnitude is above threshold, consider it a peak
            peaks.push(frequencies[i]); // Add the frequency to the peaks array
        }
    }
    
    return peaks;
}

// Example: Function to display metrics in the UI
function displayMetric(metricName, value) {
    const element = document.getElementById(metricName);
    if (element) {
        element.innerText = `${metricName}: ${value}`; // Display the calculated metric on the page
    }
}

// Automatically trigger analysis on file drop
const dragDropContainer = document.getElementById('dragDropContainer');
dragDropContainer.addEventListener('drop', function (event) {
    event.preventDefault(); // Prevent default drop behavior, important for handling files
    const files = event.dataTransfer.files; // Get the dropped files

    if (files.length > 0) { // If files are dropped, analyze the first one
        analyzeFile(files[0]);
    }
});

// Handle dragover event for the drag-and-drop container
dragDropContainer.addEventListener('dragover', function (event) {
    event.preventDefault(); // Allow dropping by overriding the default dragover behavior
});

// Automatically trigger analysis on file input change
const fileInput = document.getElementById('fileInput');
fileInput.addEventListener('change', function (event) {
    const files = event.target.files; // Get the files selected through the file input
    if (files.length > 0) { // If files are selected, analyze the first one
        analyzeFile(files[0]);
    }
});

// Function to analyze the audio file
function analyzeFile(file) {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    
    const reader = new FileReader();
    reader.onload = function () {
        audioContext.decodeAudioData(reader.result, function (buffer) {
            const channelData = buffer.getChannelData(0); // Get audio data from the first channel

            // Calculate metrics
            const rms = calculateRMS(channelData);
            const peakAmplitude = calculatePeakAmplitude(channelData);
            const zeroCrossingRate = calculateZeroCrossingRate(channelData);

            // Display calculated metrics in the UI
            displayMetric("RMS", rms);
            displayMetric("PeakAmplitude", peakAmplitude);
            displayMetric("ZeroCrossingRate", zeroCrossingRate);
        });
    };

    reader.readAsArrayBuffer(file); // Read the audio file as an array buffer
}
const audioPlayer = document.getElementById("audioPlayer");
const audioContext = new (window.AudioContext || window.webkitAudioContext)();
const sourceNode = audioContext.createMediaElementSource(audioPlayer);
const analyser = audioContext.createAnalyser();
const gainNode = audioContext.createGain();
sourceNode.connect(analyser);
sourceNode.connect(gainNode);
gainNode.connect(audioContext.destination);
analyser.fftSize = 2048;
const bufferLength = analyser.frequencyBinCount;
const dataArray = new Uint8Array(bufferLength);
const canvas = document.getElementById("spectrogramCanvas");
const canvasCtx = canvas.getContext("2d");
function drawSpectrogram() {requestAnimationFrame(drawSpectrogram); analyser.getByteFrequencyData(dataArray); canvasCtx.fillStyle = "rgb(0, 0, 0)"; canvasCtx.fillRect(0, 0, canvas.width, canvas.height); const barWidth = (canvas.width / bufferLength) * 2.5; let x = 0; for (let i = 0; i < bufferLength; i++) {const barHeight = dataArray[i]; canvasCtx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`; canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2); x += barWidth + 1;}} 
audioPlayer.addEventListener("play", () => {if (audioContext.state === "suspended") {audioContext.resume();} drawSpectrogram();});
audioPlayer.addEventListener("pause", () => {canvasCtx.clearRect(0, 0, canvas.width, canvas.height);});
function calculateSpectralCentroid(frequencies, magnitudes) {let weightedSum = 0; let totalMagnitude = 0; for (let i = 0; i < frequencies.length; i++) {weightedSum += frequencies[i] * magnitudes[i]; totalMagnitude += magnitudes[i];} return totalMagnitude === 0 ? 0 : (weightedSum / totalMagnitude).toFixed(2);}
function calculateRMS(samples) {const squaredSum = samples.reduce((sum, sample) => sum + sample * sample, 0); return Math.sqrt(squaredSum / samples.length).toFixed(2);}
function calculatePeakAmplitude(samples) {return Math.max(...samples).toFixed(2);}
function calculateZeroCrossingRate(signal) {let zeroCrossings = 0; for (let i = 1; i < signal.length; i++) {if (signal[i - 1] * signal[i] < 0) {zeroCrossings++;}} return ((zeroCrossings / signal.length) * 100).toFixed(2);}
function detectClipping(channelData) {const clippingThreshold = 1.0; const clippingRegions = []; for (let i = 0; i < channelData.length; i++) {if (Math.abs(channelData[i]) >= clippingThreshold) {clippingRegions.push(i);}} return clippingRegions;}
function extractMetadata(file) {const metadata = {}; metadata.artist = "Example Artist"; metadata.album = "Example Album"; metadata.genre = "Example Genre"; return metadata;}
function extractDuration(file) {return new Promise((resolve, reject) => {const audio = new Audio(); audio.src = URL.createObjectURL(file); audio.onloadedmetadata = function () {resolve(audio.duration);}; audio.onerror = function () {reject('Error extracting audio duration.');};});}
function extractBitrate(file) {return 320;}
function loadWaveform(file) {wavesurfer.load(URL.createObjectURL(file));}
function plotRMS(rmsValues, timeLabels) {const ctx = document.getElementById('rmsChart').getContext('2d'); const rmsChart = new Chart(ctx, {type: 'line', data: {labels: timeLabels, datasets: [{label: 'RMS', data: rmsValues, borderColor: 'rgba(75, 192, 192, 1)', fill: false}]}});}
  <script>
      // Initialize AudioContext and connect to the Audio Player
      const audioPlayer = document.getElementById("audioPlayer");
      console.log("Audio player element:", audioPlayer);

      const audioContext = new(window.AudioContext || window.webkitAudioContext)();
      console.log("AudioContext created:", audioContext);

      const sourceNode = audioContext.createMediaElementSource(audioPlayer);
      console.log("MediaElementSourceNode created:", sourceNode);

      // Create AnalyserNode for visualization
      const analyser = audioContext.createAnalyser();
      console.log("AnalyserNode created:", analyser);

      // Connect the source to the analyser
      sourceNode.connect(analyser);
      console.log("SourceNode connected to AnalyserNode");

      // Connect the analyser to the audio context's destination (output)
      const gainNode = audioContext.createGain();
      sourceNode.connect(gainNode);
      gainNode.connect(audioContext.destination);
      console.log("SourceNode connected to GainNode, GainNode connected to destination");

      // Set up the canvas for the spectrogram
      const canvas = document.getElementById("spectrogramCanvas");
      const canvasCtx = canvas.getContext("2d");
      console.log("Canvas context initialized:", canvasCtx);

      analyser.fftSize = 2048; // Adjust for resolution
      console.log("Analyser fftSize set to:", analyser.fftSize);

      const bufferLength = analyser.frequencyBinCount;
      console.log("Analyser frequencyBinCount:", bufferLength);

      const dataArray = new Uint8Array(bufferLength);
      console.log("Data array initialized:", dataArray);

      // Function to draw the spectrogram
      function drawSpectrogram() {
        try {
          console.log("Drawing spectrogram...");
          requestAnimationFrame(drawSpectrogram);
          analyser.getByteFrequencyData(dataArray);
          console.log("Frequency data retrieved:", dataArray);

          canvasCtx.fillStyle = "rgb(0, 0, 0)";
          canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

          const barWidth = (canvas.width / bufferLength) * 2.5;
          let barHeight;
          let x = 0;

          for (let i = 0; i < bufferLength; i++) {
            barHeight = dataArray[i];
            canvasCtx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`; // Adjust the color
            canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
            x += barWidth + 1;
          }
        } catch (error) {
          console.error("Error drawing the spectrogram:", error);
        }
      }

      // Volume control synchronization
      const volumeControl = document.getElementById("volumeControl"); // Assuming there's an element for volume control
      if (volumeControl) {
        volumeControl.addEventListener('input', (event) => {
          const volume = event.target.value; // Get the volume control value
          console.log("Volume control input:", volume);
          gainNode.gain.value = volume; // Update the gain node's volume
          console.log("GainNode volume set to:", volume);
        });
      }

      // Start the visualization on play
      audioPlayer.addEventListener("play", () => {
        try {
          console.log("Audio play event triggered.");
          if (audioContext.state === "suspended") {
            audioContext.resume(); // Ensure AudioContext is resumed
            console.log("AudioContext resumed.");
          }
          drawSpectrogram();
        } catch (error) {
          console.error("Error starting the spectrogram:", error);
        }
      });

      // Ensure the visualization stops when paused
      audioPlayer.addEventListener("pause", () => {
        console.log("Audio pause event triggered.");
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
      });

      // Ensure the player and analyser are synchronized when audio starts
      audioPlayer.addEventListener("play", () => {
        console.log("Audio play event triggered again.");
        audioContext.resume();
        sourceNode.connect(analyser); // Ensure the analyser node is connected after play
        console.log("SourceNode re-connected to AnalyserNode.");
      });

      // Handle pause and stop actions
      audioPlayer.addEventListener("pause", () => {
        console.log("Audio pause event triggered.");
        analyser.disconnect();
        sourceNode.disconnect();
        console.log("AnalyserNode and SourceNode disconnected.");
      });
    </script>
    23:01:17.244 Navigated to file:///C:/Users/coalesce/Documents/GitHub/EDMC-Audio-Metric-Quality-Analyser/index-1%20-%20Copy%20(2).html
23:01:17.332
Uncaught ReferenceError: WaveSurfer is not defined
    <anonymous> file:///C:/Users/coalesce/Documents/GitHub/EDMC-Audio-Metric-Quality-Analyser/js/metrics.js:7
metrics.js:7:18
    <anonymous> file:///C:/Users/coalesce/Documents/GitHub/EDMC-Audio-Metric-Quality-Analyser/js/metrics.js:7