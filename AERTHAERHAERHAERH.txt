<script src="https://cdn.jsdelivr.net/npm/wavesurfer.js"></script> <!-- For waveform visualization -->
<script src="https://cdn.jsdelivr.net/npm/fft.js"></script> <!-- For FFT calculation -->
<script>
  // Audio Context for analysis
  let audioContext = new (window.AudioContext || window.webkitAudioContext)();

  // For storing the audio file and its metadata
  let audioFile = null;
  let audioBuffer = null;

  // Elements
  const spectrogramCanvas = document.getElementById('spectrogramCanvas');
  const waveformCanvas = document.getElementById('waveformCanvas');
  const frequencyCanvas = document.getElementById('frequencyCanvas');
  const fileTable = document.getElementById('fileTable');
  const audioPropertiesTable = document.getElementById('audioPropertiesTable');
  const spectralFeaturesTable = document.getElementById('spectralFeaturesTable');
  const temporalFeaturesTable = document.getElementById('temporalFeaturesTable');
  const energyMetricsTable = document.getElementById('energyMetricsTable');
  const frequencyMetricsTable = document.getElementById('frequencyMetricsTable');

  // File upload input
  const fileInput = document.getElementById('fileInput');

  // File drop container
  const dragDropContainer = document.getElementById('dragDropContainer');

  // Create a Wavesurfer instance for waveform visualization
  let waveform = WaveSurfer.create({
    container: waveformCanvas,
    waveColor: '#1E2337',
    progressColor: '#4CAF50',
    height: 150,
  });

  // File input event listener for when files are selected
  fileInput.addEventListener('change', (event) => {
    const file = event.target.files[0];
    if (file) {
      handleFile(file);
    }
  });

  // Drag and drop event listeners
  dragDropContainer.addEventListener('dragover', (event) => {
    event.preventDefault();
    dragDropContainer.classList.add('dragging');
  });

  dragDropContainer.addEventListener('dragleave', () => {
    dragDropContainer.classList.remove('dragging');
  });

  dragDropContainer.addEventListener('drop', (event) => {
    event.preventDefault();
    dragDropContainer.classList.remove('dragging');
    const file = event.dataTransfer.files[0];
    if (file) {
      handleFile(file);
    }
  });

  // Handle file when dropped or selected
  function handleFile(file) {
    audioFile = file;
    const reader = new FileReader();

    reader.onload = (e) => {
      const arrayBuffer = e.target.result;
      audioContext.decodeAudioData(arrayBuffer, (buffer) => {
        audioBuffer = buffer;
        // Initialize and load the waveform
        waveform.loadDecodedBuffer(buffer);
        // Extract file properties
        displayFileProperties();
        // Generate metrics
        generateSpectralFeatures();
        generateTemporalFeatures();
        generateEnergyMetrics();
        generateFrequencyMetrics();
      });
    };
    reader.readAsArrayBuffer(file);
  }

  // Display file metadata
  function displayFileProperties() {
    const fileName = audioFile.name;
    const fileSize = (audioFile.size / (1024 * 1024)).toFixed(2) + ' MB';
    const lastModified = new Date(audioFile.lastModified).toLocaleString();
    const mimeType = audioFile.type;
    const fileExtension = audioFile.name.split('.').pop().toUpperCase();
    const encoding = 'UTF-8'; // assuming UTF-8 for simplicity

    // Clear current file table
    fileTable.querySelector('tbody').innerHTML = `
      <tr>
        <td>${fileName}</td>
        <td>${fileSize}</td>
        <td>${lastModified}</td>
        <td>${mimeType}</td>
        <td>.${fileExtension}</td>
        <td>${encoding}</td>
      </tr>
    `;
  }

  // Generate Spectral Features
  function generateSpectralFeatures() {
    const spectralCentroid = calculateSpectralCentroid(audioBuffer);
    const spectralFlatness = calculateSpectralFlatness(audioBuffer);
    const spectralBandwidth = calculateSpectralBandwidth(audioBuffer);
    const spectralRollOff = calculateSpectralRollOff(audioBuffer);

    spectralFeaturesTable.querySelector('tbody').innerHTML = `
      <tr><td>Spectral Centroid</td><td>${spectralCentroid.toFixed(2)} Hz</td></tr>
      <tr><td>Spectral Flatness</td><td>${spectralFlatness.toFixed(2)}</td></tr>
      <tr><td>Spectral Bandwidth</td><td>${spectralBandwidth.toFixed(2)} Hz</td></tr>
      <tr><td>Spectral Roll-off</td><td>${spectralRollOff.toFixed(2)} Hz</td></tr>
    `;
  }

  // Calculate Spectral Centroid
  function calculateSpectralCentroid(buffer) {
    // Perform FFT and compute centroid
    const fft = new FFT(buffer.length);
    fft.forward(buffer.getChannelData(0)); // Assuming mono for simplicity
    const spectrum = fft.spectrum;
    let centroid = 0;
    let sum = 0;
    for (let i = 0; i < spectrum.length; i++) {
      sum += spectrum[i];
      centroid += i * spectrum[i];
    }
    return centroid / sum;
  }

  // Calculate Spectral Flatness (simplified)
  function calculateSpectralFlatness(buffer) {
    const fft = new FFT(buffer.length);
    fft.forward(buffer.getChannelData(0));
    const spectrum = fft.spectrum;
    let geometricMean = 1;
    let arithmeticMean = 0;
    for (let i = 0; i < spectrum.length; i++) {
      arithmeticMean += spectrum[i];
      geometricMean *= spectrum[i];
    }
    geometricMean = Math.pow(geometricMean, 1 / spectrum.length);
    arithmeticMean /= spectrum.length;
    return geometricMean / arithmeticMean;
  }

  // Calculate Spectral Bandwidth
  function calculateSpectralBandwidth(buffer) {
    const fft = new FFT(buffer.length);
    fft.forward(buffer.getChannelData(0));
    const spectrum = fft.spectrum;
    let mean = 0;
    let sum = 0;
    for (let i = 0; i < spectrum.length; i++) {
      sum += spectrum[i];
      mean += i * spectrum[i];
    }
    mean /= sum;

    let bandwidth = 0;
    for (let i = 0; i < spectrum.length; i++) {
      bandwidth += Math.pow(i - mean, 2) * spectrum[i];
    }
    return Math.sqrt(bandwidth / sum);
  }

  // Calculate Spectral Roll-off
  function calculateSpectralRollOff(buffer) {
    const fft = new FFT(buffer.length);
    fft.forward(buffer.getChannelData(0));
    const spectrum = fft.spectrum;
    const threshold = 0.85; // 85% of the total energy
    let totalEnergy = 0;
    for (let i = 0; i < spectrum.length; i++) {
      totalEnergy += spectrum[i];
    }
    let cumulativeEnergy = 0;
    for (let i = 0; i < spectrum.length; i++) {
      cumulativeEnergy += spectrum[i];
      if (cumulativeEnergy / totalEnergy >= threshold) {
        return i;
      }
    }
    return spectrum.length; // Return the highest frequency if threshold is not met
  }

  // Generate Temporal Features (e.g., RMS, Peak Amplitude, etc.)
  function generateTemporalFeatures() {
    const rms = calculateRMS(audioBuffer);
    const peakAmplitude = calculatePeakAmplitude(audioBuffer);
    const zeroCrossingRate = calculateZeroCrossingRate(audioBuffer);
    const lowEnergyRatio = calculateLowEnergyRatio(audioBuffer);

    temporalFeaturesTable.querySelector('tbody').innerHTML = `
      <tr><td>RMS</td><td>${rms.toFixed(2)}</td></tr>
      <tr><td>Peak Amplitude</td><td>${peakAmplitude.toFixed(2)}</td></tr>
      <tr><td>Zero Crossing Rate</td><td>${zeroCrossingRate.toFixed(2)}%</td></tr>
      <tr><td>Low Energy Ratio</td><td>${lowEnergyRatio.toFixed(2)}%</td></tr>
    `;
  }

  // Calculate RMS (Root Mean Square)
  function calculateRMS(buffer) {
    const data = buffer.getChannelData(0);
    const squared = data.map(val => val * val);
    const mean = squared.reduce((acc, val) => acc + val, 0) / squared.length;
    return Math.sqrt(mean);
  }

  // Calculate Peak Amplitude
  function calculatePeakAmplitude(buffer) {
    const data = buffer.getChannelData(0);
    return Math.max(...data.map(Math.abs));
  }

  // Calculate Zero Crossing Rate
  function calculateZeroCrossingRate(buffer) {
    const data = buffer.getChannelData(0);
    let zeroCrossings = 0;
    for (let i = 1; i < data.length; i++) {
      if ((data[i - 1] > 0 && data[i] < 0) || (data[i - 1] < 0 && data[i] > 0)) {
        zeroCrossings++;
      }
    }
    return (zeroCrossings / data.length) * 100;
  }

  // Calculate Low Energy Ratio
  function calculateLowEnergyRatio(buffer) {
    const data = buffer.getChannelData(0);
    let lowEnergy = 0;
    let threshold = 0.1;
    for (let i = 0; i < data.length; i++) {
      if (Math.abs(data[i]) < threshold) {
        lowEnergy++;
      }
    }
    return (lowEnergy / data.length) * 100;
  }

  // Generate Energy Metrics
  function generateEnergyMetrics() {
    // Placeholder: Just example values
    energyMetricsTable.querySelector('tbody').innerHTML = `
      <tr><td>Total Energy</td><td>125 J</td></tr>
      <tr><td>Mean Energy</td><td>2.5 J</td></tr>
      <tr><td>Energy Distribution (Bass)</td><td>35%</td></tr>
      <tr><td>Energy Distribution (Treble)</td><td>40%</td></tr>
    `;
  }

  // Generate Frequency Metrics
  function generateFrequencyMetrics() {
    frequencyMetricsTable.querySelector('tbody').innerHTML = `
      <tr><td>Frequency Peaks</td><td>1000 Hz, 2000 Hz</td></tr>
      <tr><td>Octave Bands</td><td>90 dB, 80 dB</td></tr>
      <tr><td>Harmonic Ratio</td><td>85%</td></tr>
      <tr><td>Dominant Frequency</td><td>1200 Hz</td></tr>
    `;
  }

</script>
<script>
  // Function to generate the Spectrogram visualization
  function generateSpectrogram(buffer) {
    const canvasContext = spectrogramCanvas.getContext('2d');
    const analyser = audioContext.createAnalyser();
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(analyser);
    analyser.connect(audioContext.destination);

    analyser.fftSize = 512;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    source.start();

    function drawSpectrogram() {
      analyser.getByteFrequencyData(dataArray);
      canvasContext.clearRect(0, 0, spectrogramCanvas.width, spectrogramCanvas.height);

      // Draw the spectrogram
      for (let i = 0; i < bufferLength; i++) {
        const barHeight = dataArray[i] / 255 * spectrogramCanvas.height;
        canvasContext.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
        canvasContext.fillRect(i * 2, spectrogramCanvas.height - barHeight, 2, barHeight);
      }

      requestAnimationFrame(drawSpectrogram);
    }

    drawSpectrogram();
  }

  // Generate Frequency Spectrum visualization
  function generateFrequencySpectrum(buffer) {
    const canvasContext = frequencyCanvas.getContext('2d');
    const analyser = audioContext.createAnalyser();
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(analyser);
    analyser.connect(audioContext.destination);

    analyser.fftSize = 1024;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    source.start();

    function drawFrequencySpectrum() {
      analyser.getByteFrequencyData(dataArray);
      canvasContext.clearRect(0, 0, frequencyCanvas.width, frequencyCanvas.height);

      const barWidth = (frequencyCanvas.width / bufferLength) * 2.5;
      let barHeight;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        barHeight = dataArray[i] / 255 * frequencyCanvas.height;
        canvasContext.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
        canvasContext.fillRect(x, frequencyCanvas.height - barHeight, barWidth, barHeight);
        x += barWidth + 1;
      }

      requestAnimationFrame(drawFrequencySpectrum);
    }

    drawFrequencySpectrum();
  }

  // Generate Energy Metrics (Total, Mean, Bass, Treble)
  function generateEnergyMetrics() {
    const data = audioBuffer.getChannelData(0); // Assuming mono for simplicity
    const totalEnergy = data.reduce((acc, value) => acc + (value * value), 0);
    const meanEnergy = totalEnergy / data.length;
    const bassEnergy = data.slice(0, data.length / 2).reduce((acc, value) => acc + (value * value), 0);
    const trebleEnergy = data.slice(data.length / 2).reduce((acc, value) => acc + (value * value), 0);

    energyMetricsTable.querySelector('tbody').innerHTML = `
      <tr><td>Total Energy</td><td>${totalEnergy.toFixed(2)} J</td></tr>
      <tr><td>Mean Energy</td><td>${meanEnergy.toFixed(2)} J</td></tr>
      <tr><td>Energy Distribution (Bass)</td><td>${((bassEnergy / totalEnergy) * 100).toFixed(2)}%</td></tr>
      <tr><td>Energy Distribution (Treble)</td><td>${((trebleEnergy / totalEnergy) * 100).toFixed(2)}%</td></tr>
    `;
  }

  // Generate Frequency Metrics (Peaks, Octave Bands, Harmonic Ratio, Dominant Frequency)
  function generateFrequencyMetrics() {
    const fft = new FFT(audioBuffer.length);
    fft.forward(audioBuffer.getChannelData(0));

    const spectrum = fft.spectrum;
    const maxIndex = spectrum.indexOf(Math.max(...spectrum)); // Dominant Frequency
    const dominantFrequency = maxIndex * audioContext.sampleRate / spectrum.length;

    // Example metrics
    const frequencyPeaks = [1000, 2000]; // Dummy values for demonstration
    const octaveBands = [90, 80]; // Dummy values
    const harmonicRatio = 85; // Dummy value

    frequencyMetricsTable.querySelector('tbody').innerHTML = `
      <tr><td>Frequency Peaks</td><td>${frequencyPeaks.join(' Hz, ')}</td></tr>
      <tr><td>Octave Bands</td><td>${octaveBands.join(' dB, ')}</td></tr>
      <tr><td>Harmonic Ratio</td><td>${harmonicRatio}%</td></tr>
      <tr><td>Dominant Frequency</td><td>${dominantFrequency.toFixed(2)} Hz</td></tr>
    `;
  }

  // Display Audio Properties (Sample Rate, Duration, Channels)
  function displayAudioProperties() {
    const sampleRate = audioBuffer.sampleRate;
    const duration = audioBuffer.duration;
    const channels = audioBuffer.numberOfChannels;

    audioPropertiesTable.querySelector('tbody').innerHTML = `
      <tr><td>Sample Rate</td><td>${sampleRate} Hz</td></tr>
      <tr><td>Channels</td><td>${channels}</td></tr>
      <tr><td>Duration</td><td>${formatTime(duration)}</td></tr>
    `;
  }

  // Helper function to format time in seconds to mm:ss format
  function formatTime(seconds) {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = Math.floor(seconds % 60);
    return `${minutes}:${remainingSeconds < 10 ? '0' : ''}${remainingSeconds}`;
  }

  // Call all the analysis and visualizations once the audio is loaded
  function handleFile(file) {
    const reader = new FileReader();
    reader.onload = (e) => {
      const arrayBuffer = e.target.result;
      audioContext.decodeAudioData(arrayBuffer, (buffer) => {
        audioBuffer = buffer;

        // Start processing and visualizations
        displayAudioProperties();
        generateSpectrogram(buffer);
        generateFrequencySpectrum(buffer);
        generateEnergyMetrics();
        generateFrequencyMetrics();
      });
    };
    reader.readAsArrayBuffer(file);
  }

</script>
AERH